{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulcodrea/reddit_humor/blob/main/2a_keras-tokenize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTI_jxV_7R56",
        "outputId": "e7b42c12-5733-43f5-d117-e0fc34437707"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\paulc\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout \n",
        "from keras.layers import LSTM, Embedding\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvpRiHqs53Vu",
        "outputId": "ccc504f4-a943-47e8-dcf2-cdbfdbcec83e"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "ZzV9t8t87ZOw"
      },
      "outputs": [],
      "source": [
        "# We might have to change the following\n",
        "\n",
        "config = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 3, \n",
        "    \"batch_size\": 70,\n",
        "    \"train_p\": 0.7,\n",
        "    \"test_p\": 0.2,\n",
        "    \"val_p\": 0.1,\n",
        "    # \"LSTM_layer\": [50, 10],\n",
        "    # \"Dropout_layer\": [0.5],\n",
        "    # \"activation\": 'sigmoid',\n",
        "    ##################### SAVE FOR LIVE DEMO #############################\n",
        "    \"model_path\": './model/2a_model.h5',\n",
        "    \"tokenizer_path\": './model/2a_tokenizer.pickle',\n",
        "    \"data_path\": \"model/2a_data.csv\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "_McP__5n5US1"
      },
      "outputs": [],
      "source": [
        "class LSTM_model:\n",
        "    def __init__(self, path):\n",
        "        \"\"\"\n",
        "        Initializes the class.\n",
        "        \"\"\"\n",
        "        self.path = path # Path to the dataset\n",
        "        self.data = pd.DataFrame() # Dataframe to store the dataset\n",
        "\n",
        "        self.vocabulary_size = 0\n",
        "        self.tokenizer = Tokenizer(num_words=None, split=' ')\n",
        "\n",
        "        self.jokes_to_numerical = []\n",
        "        self.model = None\n",
        "\n",
        "\n",
        "    def read_dataset(self):\n",
        "        \"\"\"\n",
        "        Reads the dataset from the given path.\n",
        "        \"\"\"\n",
        "        ret = pd.read_csv(self.path)\n",
        "        ret.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "        count_zero = count_one = 0\n",
        "        # check at which index the joke is 0 or 1\n",
        "        for index, row in ret.iterrows():\n",
        "            if row['funny'] == 0:\n",
        "                count_zero += 1\n",
        "            else:\n",
        "                count_one += 1\n",
        "\n",
        "        print(\"The input has {} jokes with 0 and {} jokes with 1\".format(count_zero, count_one))\n",
        "\n",
        "        self.data = ret\n",
        "\n",
        "\n",
        "    def set_vocabulary_size(self, size):\n",
        "        \"\"\"\n",
        "        Sets the vocabulary size.\n",
        "        \"\"\"\n",
        "        self.vocabulary_size = size\n",
        "\n",
        "\n",
        "    def convert_jokes_to_numerical(self, max_length):\n",
        "        \"\"\"\n",
        "        Converts the jokes to numerical values.\n",
        "        \"\"\"\n",
        "        self.tokenizer.fit_on_texts(self.data['clean_text'].values) # fit the tokenizer\n",
        "        self.jokes_to_numerical = self.tokenizer.texts_to_sequences(self.data['clean_text'].values) # convert jokes to numerical values\n",
        "        self.jokes_to_numerical = pad_sequences(self.jokes_to_numerical, maxlen=max_length) # pad the sequences\n",
        "\n",
        "        self.vocabulary_size = len(self.tokenizer.word_index) + 1 # +1 for the unknown token\n",
        "\n",
        "\n",
        "    def split_dataset(self, X_dataset, y_dataset):\n",
        "        \"\"\"\n",
        "        Splits the dataset into training and testing sets.\n",
        "        \"\"\"\n",
        "        X = X_dataset\n",
        "        y = y_dataset\n",
        "\n",
        "        # convert X as a numpy array float32\n",
        "        X = np.array(X, dtype=np.float32)\n",
        "        y = np.array(y, dtype=np.float32)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=config['test_p'], \n",
        "                                                            random_state=42)\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "    def LSTM_model(self, max_length):\n",
        "        \"\"\"\n",
        "        Splits the data into train and validation sets.\n",
        "        Constructs the LSTM model.\n",
        "        \"\"\"\n",
        "        X_train, X_test, y_train, y_test = self.split_dataset(X_dataset=self.jokes_to_numerical, \n",
        "                                                              y_dataset=self.data['funny'])\n",
        "\n",
        "        \n",
        "        # define the model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Embedding(input_dim=self.vocabulary_size, output_dim=max_length, \n",
        "                                 input_length=int(X_train.shape[1])))\n",
        "        self.model.add(LSTM(units=50, return_sequences=True))\n",
        "        self.model.add(LSTM(units=10))\n",
        "        self.model.add(Dropout(0.5))\n",
        "        self.model.add(Dense(units=1, activation='sigmoid'))\n",
        "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        self.model.summary()\n",
        "        self.model.fit(X_train, y_train, epochs=config['epochs'], batch_size=config['batch_size'], \n",
        "                       verbose='auto', validation_split=config['val_p'])\n",
        "\n",
        "        self.evaluate_model(X_test, y_test, max_length) # evaluate the model\n",
        "\n",
        "\n",
        "    def evaluate_model(self, X_test, y_test, max_length):\n",
        "        \"\"\"\n",
        "        Evaluates the model.\n",
        "        \"\"\"\n",
        "        scores = self.model.evaluate(X_test, y_test)\n",
        "        print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
        "\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_pred = np.round(y_pred)\n",
        "\n",
        "        # create precision, recall, f1 manually\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        print(\"Precision: %.2f%%\" % (precision * 100))\n",
        "        print(\"Recall: %.2f%%\" % (recall * 100))\n",
        "        print(\"F1-Score: %.2f%%\" % (f1 * 100))\n",
        "\n",
        "        # Save data\n",
        "        self.save_data(max_length, scores[1], precision, recall, f1)\n",
        "\n",
        "    def save_data(self, max_length, accuracy, precision, recall, f1):\n",
        "        \"\"\"\n",
        "        Saves the data.\n",
        "        \"\"\"\n",
        "        # Add in dataframe master_df max_len, accuracy, precision, recall, f1-score\n",
        "        ret = pd.DataFrame(columns=['max_len', 'accuracy', 'precision', 'recall', 'f1-score'])\n",
        "        ret.loc[0] = [max_length, accuracy, precision, recall, f1]\n",
        "        ret.to_csv(config['data_path'])\n",
        "        \n",
        "        self.model.save(config['model_path']) # save the model\n",
        "\n",
        "        # save the tokenizer\n",
        "        with open(config['tokenizer_path'], 'wb') as handle:\n",
        "            pickle.dump(self.tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read data and pre-process it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "NRyY8hOIG6hX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The input has 1459 jokes with 0 and 1459 jokes with 1\n",
            "Max length of joke:  124\n",
            "Vocabulary size:  9136\n"
          ]
        }
      ],
      "source": [
        "# SETTINGS for local machine - change this for Goolg Colab\n",
        "# path = \"dataset/final_jokes(2918).csv\" \n",
        "path = \"dataset/final_jokes_and_facts(2918).csv\" # DATASET WITH FACTS\n",
        "\n",
        "#path = \"/content/drive/MyDrive/NLU_Humor-detection/final_jokes(1283).csv\"\n",
        "\n",
        "joke_model = LSTM_model(path)\n",
        "joke_model.read_dataset()\n",
        "\n",
        "max_length_joke = joke_model.data['token_count'].max()\n",
        "joke_model.convert_jokes_to_numerical(max_length_joke) # convert the jokes to numerical values\n",
        "\n",
        "print(\"Max length of joke: \", max_length_joke)\n",
        "print(\"Vocabulary size: \", joke_model.vocabulary_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model & Save the model (for live demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 124, 124)          1132864   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 124, 50)           35000     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 10)                2440      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,170,315\n",
            "Trainable params: 1,170,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "30/30 [==============================] - 7s 161ms/step - loss: 0.5722 - accuracy: 0.7619 - val_loss: 0.3857 - val_accuracy: 0.8761\n",
            "Epoch 2/3\n",
            "30/30 [==============================] - 4s 128ms/step - loss: 0.3017 - accuracy: 0.9267 - val_loss: 0.1803 - val_accuracy: 0.9786\n",
            "Epoch 3/3\n",
            "30/30 [==============================] - 4s 143ms/step - loss: 0.1425 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.9915\n",
            "19/19 [==============================] - 1s 32ms/step - loss: 0.0889 - accuracy: 0.9863\n",
            "Accuracy: 98.63%\n",
            "Precision: 99.35%\n",
            "Recall: 98.08%\n",
            "F1-Score: 98.71%\n"
          ]
        }
      ],
      "source": [
        "joke_model.LSTM_model(max_length_joke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a3a52a35f691380e40dee258b5f482ebea5e8d938b654dd4fe14bb13e1a5bfa7"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
