{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2d_word_freq.ipynb",
      "provenance": [],
      "mount_file_id": "1K8HXEwh66tlUswBm6dMTIUTsYWvLvVIN",
      "authorship_tag": "ABX9TyOhl7dV8GvN0L65CXgiaNtc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulcodrea/reddit_humor/blob/main/2d_word_freq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCHqjXtvqlOz",
        "outputId": "4baeb03a-7323-4a4a-fe5b-1750052df16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import nltk\n",
        "from nltk import word_tokenize, RegexpTokenizer\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/Humour_Detection_Dataset/final_jokes_and_facts(2918).csv'\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "print(\"Data successfuly read!\")\n",
        "\n",
        "print(\"This is the first line from the data file: \\n\", data.head(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-U63FoNqsv7",
        "outputId": "9f3dd533-65bb-4b0f-bc08-a25bcaabb531"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfuly read!\n",
            "This is the first line from the data file: \n",
            "    Unnamed: 0                                               joke  \\\n",
            "0           0  Did you hear about the band that had a flexibl...   \n",
            "\n",
            "                                              tokens  token_count  funny  \\\n",
            "0  ['Did', 'hear', 'band', 'flexible', 'schedule'...            9      1   \n",
            "\n",
            "                                          clean_text  \n",
            "0  did hear band flexible schedule they called ru...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenise_clean_text(data_set):\n",
        "  \"\"\"\n",
        "  Tokenises the data from the CSV file.\n",
        "  \"\"\"\n",
        "  arr = []\n",
        "  for line in data_set['clean_text']:\n",
        "    arr.append(line.split(' '))\n",
        "  arr = [x[:(len(x) - 1)] for x in arr]\n",
        "  return arr\n",
        "\n",
        "def return_vocab(document) -> list:\n",
        "  \"\"\"\n",
        "  Retuns the vocabulary of a document.\n",
        "  \"\"\"\n",
        "  computed_vocab = []\n",
        "  for line in document:\n",
        "    for word in line:\n",
        "      computed_vocab.append(word)\n",
        "  computed_vocab = list(dict.fromkeys(computed_vocab))\n",
        "  return computed_vocab\n",
        "\n",
        "def document_frequency(vocabulary: dict, jokes: list):\n",
        "  \"\"\"\n",
        "  Returns a dictionary where the keys are all words in the vocabulary and the \n",
        "  values the list of jokes the word appears in.\n",
        "  \"\"\"\n",
        "  doc_freq = {}\n",
        "  for word in vocabulary:\n",
        "    doc_freq[word] = 0\n",
        "  for joke in jokes:\n",
        "    for joke_word in joke:\n",
        "      doc_freq[joke_word] = doc_freq[joke_word] + 1\n",
        "  return doc_freq\n",
        "\n",
        "def find_max_joke_size(joke_list):\n",
        "  max_size = 0\n",
        "  for joke in joke_list:\n",
        "    if len(joke) > max_size:\n",
        "      max_size = len(joke)\n",
        "  return max_size"
      ],
      "metadata": {
        "id": "2AVIU2_QquqZ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_jokes_tokenized = tokenise_clean_text(data)\n"
      ],
      "metadata": {
        "id": "lz71a5E6q2jj"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = return_vocab(list_jokes_tokenized)"
      ],
      "metadata": {
        "id": "N9E-prFjrIMI"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voc_freq = document_frequency(vocabulary, list_jokes_tokenized)"
      ],
      "metadata": {
        "id": "eYA8Z8ucrLiu"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_size = find_max_joke_size(list_jokes_tokenized)"
      ],
      "metadata": {
        "id": "MmaKS2Tvt9ir"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def jokes_as_values(vocabulary_frequency, jokes, max_size):\n",
        "#   embedded_joke = np.zeros((len(jokes), max_size))\n",
        "#   index_joke = 0\n",
        "#   for joke in jokes:\n",
        "#     index_word = 0\n",
        "#     joke_list = np.zeros((len(joke)))\n",
        "#     for word in joke:\n",
        "#       joke_list[index_word] = vocabulary_frequency[word]\n",
        "#       index_word = index_word +1\n",
        "#     joke_list = sequence.pad_sequences(joke_list, maxlen=max_size)\n",
        "#     embedded_joke[index_joke]= joke_list\n",
        "\n",
        "#     index_joke = index_joke + 1\n",
        "#   return embedded_joke"
      ],
      "metadata": {
        "id": "6HFrlBM5sWf7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jokes_as_vectors = []\n",
        "for joke in list_jokes_tokenized:\n",
        "  joke_list = np.zeros((len(joke)))\n",
        "  index = 0\n",
        "  for word in joke:\n",
        "    joke_list[index] = voc_freq[word]\n",
        "    index = index + 1\n",
        "  jokes_as_vectors.append(joke_list)\n",
        "   \n"
      ],
      "metadata": {
        "id": "wK9kWpg1wOsY"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n3_BJ3fYwvMs"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jokes_as_vectors = np.asarray(jokes_as_vectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61fmRmaixXh4",
        "outputId": "a1407f22-d8d7-42a4-ab48-2bacbe5ae95c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_arr = np.zeros((len(jokes_as_vectors), max_size), dtype=int)\n",
        "old_arr = jokes_as_vectors\n",
        "for idx, joke in enumerate(jokes_as_vectors):\n",
        "  len_joke = len(joke)\n",
        "  joke_x = jokes_as_vectors[idx]\n",
        "  new_arr[idx] = np.append([0] * (max_size - len_joke), joke)\n",
        "\n",
        "print(new_arr.shape)\n",
        "jokes_as_vectors = new_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxP7Z55qwyfX",
        "outputId": "0e332538-ea61-4937-a720-d2fbeb91f0af"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2918, 140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(jokes_as_vectors[0])"
      ],
      "metadata": {
        "id": "aWa9IpPLutLi"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jokes_as_vectors[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk9BVWZYDI6v",
        "outputId": "01d7c596-b4b6-4834-fb22-5d4186e3308f"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  48,  33,   7,   5,   2, 177, 105,   8,   7],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 883,\n",
              "          3,  92,   5, 883,  26,  10,  20,   4,  28,  42],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 574,   4,   2,  90,   2,   6,   2,   5,  38, 117, 574,\n",
              "         19,   6,   6,  18,   2,   8,   2,  13,  86, 118,   5,   4,   2,\n",
              "         20,   2,   2,  13,   2,   2, 103,   6,  10,  92],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,  74,  74,  31,   2,  48,  32,   8,\n",
              "         16,  16,  71, 128, 150, 146,  74,   8,  16, 157,  31,   2,  50,\n",
              "        574,  48,  12,  50,   2,   2, 111,  64, 149,  70],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 147,   1,  22,   1,  29,  90,   2,  29,   3],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        102,  90,  44, 883,  26,   2,   2, 883,  29,  12],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         87, 111,  10,   4, 150, 146,   2,   2,  16,   2],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 255, 220,   7,   4,  54,   4,   2,   2,  36,   4,\n",
              "          2,   2,  19,   3,   2, 220, 171,  17,   4,   6],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  16, 149,  26, 111,  12,  14,   9,   1,  47,  37, 149,  29,\n",
              "         64, 119,  15,  19,   5,   1,  33,   1,   3,   1],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  27,   3,  18,   1,  12, 102,   1,   3,  64, 149,  48,\n",
              "          1,  13,   1, 128,  23,   1,   5,  20,   9,   5]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_test_data(jokes_list, corpus, max_joke):\n",
        "  train_max_index = int(len(jokes_list) * 0.8)\n",
        "  X_train = np.zeros(shape=(train_max_index, max_joke), dtype=int)\n",
        "  X_test = np.zeros(shape=(len(jokes_list) - train_max_index, max_joke), dtype=int)\n",
        "  index_returned_data = 0\n",
        "  for index in range(0, train_max_index):\n",
        "    X_train[index_returned_data] = jokes_list[index]\n",
        "    index_returned_data = index_returned_data + 1\n",
        "  y_train = corpus[\"funny\"][:train_max_index]\n",
        "  index_returned_data = 0\n",
        "  for index in range(train_max_index, len(jokes_list)):\n",
        "    X_test[index_returned_data] = jokes_list[index]\n",
        "    index_returned_data = index_returned_data + 1\n",
        "  y_test = corpus[\"funny\"][train_max_index:]\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "ME0sB-zSx4_Y"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = generate_train_test_data(jokes_as_vectors, data, max_size)"
      ],
      "metadata": {
        "id": "Sn6x5LKzx-Pg"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrXbZavQ0Ljg",
        "outputId": "25bb634b-d398-4995-e3eb-528128bc5e3d"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  48  33   7   5   2 177 105   8   7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62hnJ3lc0Opz",
        "outputId": "3faf845c-0926-4d57-a36b-521e9716dbf5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "4    1\n",
            "5    1\n",
            "6    0\n",
            "7    0\n",
            "8    0\n",
            "9    0\n",
            "Name: funny, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "funny = 0\n",
        "for item in y_train:\n",
        "  funny = funny + item\n",
        "print(funny)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Ry489y2Ju5",
        "outputId": "05930909-b499-4810-8c74-2c0944fbe2dc"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(vocabulary), embedding_vecor_length, input_length=max_size))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8k4yO1VxzrQ",
        "outputId": "23f7fce7-5787-4ec7-d41c-2353e1d1cce7"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 140, 32)           292288    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               53200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 345,589\n",
            "Trainable params: 345,589\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "37/37 [==============================] - 9s 190ms/step - loss: 0.5536 - accuracy: 0.7309 - val_loss: 0.4675 - val_accuracy: 0.8014\n",
            "Epoch 2/3\n",
            "37/37 [==============================] - 6s 175ms/step - loss: 0.3496 - accuracy: 0.8650 - val_loss: 0.3436 - val_accuracy: 0.8545\n",
            "Epoch 3/3\n",
            "37/37 [==============================] - 8s 211ms/step - loss: 0.2495 - accuracy: 0.9006 - val_loss: 0.2340 - val_accuracy: 0.9127\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cb7a423d0>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "4N5dlceV3obs"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_test\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "jWw7xE9Jy1iz"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_pred)"
      ],
      "metadata": {
        "id": "_jls0uuXy8Ya"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62V2UVuGzAfL",
        "outputId": "7ca7270b-0b22-4956-e86c-4a3f18a57e84"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 91.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0yTTQfUWDz-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}