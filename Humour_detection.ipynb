{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulcodrea/reddit_humor/blob/main/Humour_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o1_DyllE0pbH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5sJJRgw28QT"
      },
      "source": [
        "### Defining methods useful for scraping the Reddit threads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b4H-JgsV3B5k"
      },
      "outputs": [],
      "source": [
        "def scrape_url(url, pages=0):\n",
        "  \"\"\" \n",
        "  Scrapes a url and returns a list.\n",
        "  \"\"\"\n",
        "\n",
        "  resp = requests.get(url=url, headers = {'User-agent': 'Humour detection bot'}, params = {'limit': '100'})\n",
        "  data = resp.json()\n",
        "  ret = []\n",
        "  ret.append(data)\n",
        "  \n",
        "  # if more than 100 data points are needed:\n",
        "  if pages != 0:\n",
        "    for i in range(pages):\n",
        "      after_param = data['data']['after'] \n",
        "      data = requests.get(url=url, headers = {'User-agent': 'Humour detection bot'}, params = {'after': after_param, 'limit': '100'})\n",
        "      data_2 = data.json()\n",
        "      ret.append(data_2)\n",
        "      data = data_2\n",
        "\n",
        "  return ret\n",
        "\n",
        "def make_list_from_json(json_list):\n",
        "  \"\"\"\n",
        "  Makes a list from a json list.\n",
        "  \"\"\"\n",
        "\n",
        "  ret = []\n",
        "  for collection in json_list:\n",
        "    collection_list = collection['data']['children']\n",
        "    for joke_index in range(len(collection_list)):\n",
        "      ret.append(collection_list[joke_index]['data'])\n",
        "  return ret\n",
        "\n",
        "def transform_data(data):\n",
        "  \"\"\" \n",
        "  Transforms data to a dataframe. Ans only keeps the columns that are needed.\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(data)\n",
        "  ret = pd.DataFrame()\n",
        "\n",
        "  ret['title'] = df['title']\n",
        "  ret['selftext'] = df['selftext']\n",
        "  ret['ups'] = df['ups']\n",
        "  ret['downs'] = df['downs']\n",
        "  ret['upvote_ratio'] = df['upvote_ratio']\n",
        "  ret['total_awards_received'] = df['total_awards_received']\n",
        "\n",
        "  return ret\n",
        "\n",
        "def preprocess(data):\n",
        "  \"\"\"\n",
        "  Preprocesses data to concatenate title and punchline into one string.\n",
        "  \"\"\"\n",
        "\n",
        "  data['joke'] = ''\n",
        "  for joke_index in range(len(data)):\n",
        "    title = data['title'][joke_index]\n",
        "    separator = ' '\n",
        "    if title[len(title) - 1].isalpha():\n",
        "        separator = '. '\n",
        "    data['joke'][joke_index] = data['title'][joke_index] + separator + data['selftext'][joke_index] \n",
        "    joke = data['joke'][joke_index]\n",
        "    if joke[len(joke) - 1].isalpha():\n",
        "      data['joke'][joke_index] = joke + '.'\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFcJ67yu2W0_"
      },
      "source": [
        "# Scraping r/dadjokes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7gxCeyWG0pbK"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.reddit.com/r/dadjokes.json\"\n",
        "data = scrape_url(url, 100)\n",
        "data = make_list_from_json(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3R-7RcKXTzY"
      },
      "source": [
        "### Save only important columns in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f5mn3L3SXTzZ"
      },
      "outputs": [],
      "source": [
        "clean_df = transform_data(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wfMpvJFXTza"
      },
      "source": [
        "### Plot the stats of the reddit jokes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "XAPmfh9i0pbO",
        "outputId": "81fa0583-7ca8-4490-b3df-59b7c3b24dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of jokes with upvotes different from zero:  8960\n",
            "Number of jokes with no engagement:  568\n",
            "Average number of upvotes:  228.58354324097397\n",
            "Average upvote ratio:  0.842445424013434\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# print out as a pie chart how many jokes are funny or not\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# calculate number of posts with upvotes different grater than downvotes\n",
        "funny = clean_df[clean_df['ups'] > clean_df['downs']]\n",
        "# not_funny = clean_df[clean_df['ups'] <= clean_df['downs']]\n",
        "no_engagement = len(clean_df[(clean_df['ups'] == 0) & (clean_df['downs'] == 0)])\n",
        "\n",
        "\n",
        "#calculate how many have only upvotes and zero downvotes\n",
        "upvotes_count = downvotes_count = 0\n",
        "for index in range(len(clean_df)):\n",
        "    if clean_df['ups'][index] > 0:\n",
        "        upvotes_count += 1\n",
        "\n",
        "print(\"Number of jokes with upvotes different from zero: \", upvotes_count)\n",
        "print(\"Number of jokes with no engagement: \", no_engagement)\n",
        "\n",
        "treshhold_ups = clean_df['ups'].mean()\n",
        "print(\"Average number of upvotes: \", treshhold_ups)\n",
        "threshold_ratio = clean_df['upvote_ratio'].mean()\n",
        "print(\"Average upvote ratio: \", threshold_ratio)\n",
        "\n",
        "\n",
        "funny_percentage = len(funny) / len(clean_df) * 100\n",
        "no_engagement_percentage = no_engagement / len(clean_df) * 100\n",
        "\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.pie([funny_percentage, no_engagement_percentage], labels=['funny', 'not funny'], autopct='%1.1f%%', colors=['green', 'red'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7FOz4TnkUFP"
      },
      "source": [
        "Experimenting to find a threshold "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S30tUqCSXTzc",
        "outputId": "ba414015-4595-48d8-fafd-96b0d7b4851b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total  9528\n",
            "not that funny but have awards  0\n",
            "funny  683\n",
            "funny ratio  0.07168345927791772\n"
          ]
        }
      ],
      "source": [
        "unfunny_but_awarded = 0\n",
        "funny = 0\n",
        "count = 0\n",
        "jokes_dataset = pd.DataFrame()\n",
        "for index in range(len(clean_df)):\n",
        "\n",
        "  if clean_df['ups'][index] > treshhold_ups and clean_df['upvote_ratio'][index] > threshold_ratio:\n",
        "    jokes_dataset = jokes_dataset.append(clean_df.iloc[count])\n",
        "    count = count + 1\n",
        "    funny = funny + 1\n",
        "\n",
        "\n",
        "\n",
        "print('total ', len(clean_df))\n",
        "print('not that funny but have awards ', unfunny_but_awarded)\n",
        "print('funny ', funny)\n",
        "print('funny ratio ', funny/len(clean_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvvqkbuEpeYI",
        "outputId": "53fa0f40-b06a-4e35-b58e-b941c8c9099d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The highest length of title is  260\n",
            "The highest length og the joke is:  1778\n"
          ]
        }
      ],
      "source": [
        "# add one more column to jokes_dataset with length of selftext\n",
        "jokes_dataset['title_length'] = jokes_dataset['title'].apply(len)\n",
        "jokes_dataset['selftext_length'] = jokes_dataset['selftext'].apply(len)\n",
        "print(\"The highest length of title is \", jokes_dataset['title_length'].max())\n",
        "print(\"The highest length og the joke is: \", jokes_dataset['selftext_length'].max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rJaedS020pbR"
      },
      "outputs": [],
      "source": [
        "# save jokes_dataset in a csv file\n",
        "jokes_dataset.to_csv(f'reddit_funny_dadjokes({len(jokes_dataset)}).csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bnym-oJ2g7A"
      },
      "source": [
        "# Scraping r/badjokes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zS1CQFiK2lS1"
      },
      "outputs": [],
      "source": [
        "# Get reddit /r/badjokes data\n",
        "url = \"https://www.reddit.com/r/badjokes.json\"\n",
        "data_neg = scrape_url(url, 5)\n",
        "data_neg = make_list_from_json(data_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmF6tVWq2yu7"
      },
      "source": [
        "### Save only important columns in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gdLGrfYa2zor"
      },
      "outputs": [],
      "source": [
        "badjokes_dataset = transform_data(data_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0hVTy5h6Cxe",
        "outputId": "3eb83483-51f3-4d2e-d0d6-ff527ed102d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "600\n"
          ]
        }
      ],
      "source": [
        "print(len(badjokes_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pZP8UOjE63TD"
      },
      "outputs": [],
      "source": [
        "# save jokes_dataset in a csv file\n",
        "badjokes_dataset.to_csv(f'reddit_badjokes({len(badjokes_dataset)}).csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a single dataframe with all content and 0/1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0                 What's so good about Soviet Ubers?   \n",
            "1                             Why was 9 afraid of 7?   \n",
            "2     What's a candle's favorite Keanu Reeves movie?   \n",
            "3  No-one in the Government has played Hospital T...   \n",
            "4           What is the most pathetic kind of shape?   \n",
            "\n",
            "                         selftext  ups  downs  upvote_ratio  \\\n",
            "0          They're always Russian  194      0          1.00   \n",
            "1  7 was a registered 6 offender.  385      0          0.99   \n",
            "2                       John Wick  120      0          1.00   \n",
            "3                                   51      0          0.97   \n",
            "4                  \\n\\nRektangles   68      0          0.99   \n",
            "\n",
            "   total_awards_received  funny  \n",
            "0                      3      0  \n",
            "1                      3      0  \n",
            "2                      0      0  \n",
            "3                      0      0  \n",
            "4                      0      0  \n"
          ]
        }
      ],
      "source": [
        "# Create one more column for jokes_dataset filles with 1\n",
        "jokes_dataset['funny'] = 1\n",
        "badjokes_dataset['funny'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTY6U2yaSKEw"
      },
      "source": [
        "### Data Pre-processing - WIP\n",
        "\n",
        "### and save the final_df with jokes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzb85_UzSOfS",
        "outputId": "adeb8a01-cd0b-4afa-f692-12deb8832d47"
      },
      "outputs": [],
      "source": [
        "jokes_dataset = preprocess(jokes_dataset)\n",
        "badjokes_dataset = preprocess(badjokes_dataset)\n",
        "\n",
        "# create final_df with jokes_dataset specific columns\n",
        "final_df = pd.DataFrame()\n",
        "final_df['joke'] = jokes_dataset['joke']\n",
        "final_df['funny'] = jokes_dataset['funny']\n",
        "\n",
        "#concat to final_df with badjokes_dataset specific columns\n",
        "final_df = final_df.append(badjokes_dataset, ignore_index=True)\n",
        "# remove title, selftext, ups, downs, upvote_ratio, total_awards_received\n",
        "final_df = final_df.drop(['title', 'selftext', 'ups', 'downs', 'upvote_ratio', 'total_awards_received'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save final_df in a csv file\n",
        "final_df.to_csv(f'final_jokes({len(final_df)}).csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLasb865klgW"
      },
      "source": [
        "### Experiment with similarity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTZN2z5jnakm",
        "outputId": "a16c2f1c-ed53-43c9-d50f-2f35f4f21f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "651\n"
          ]
        }
      ],
      "source": [
        "normalised_jokes = []\n",
        "for joke_index in range(len(jokes_dataset)):\n",
        "  if jokes_dataset['title_length'][joke_index] + jokes_dataset['selftext_length'][joke_index] < 200:\n",
        "    normalised_jokes.append(joke_index)\n",
        "print(len(normalised_jokes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRhf1HR_dxMa",
        "outputId": "168e20df-b760-4cce-d3ab-b3911c135816"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\paulc\\AppData\\Local\\Temp/ipykernel_20360/3608984461.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  jokes_dataset['similarity'][joke_index] = final_score\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I went to get pizza the other day and they asked if I wanted it cut into eight slices. I told them thereâ€™s no way I can eat eight slices in one sitting and had them cut it into four.\n"
          ]
        }
      ],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "max = 0\n",
        "index_similar = 0\n",
        "jokes_dataset['similarity'] = ''\n",
        "for joke_index in range(len(jokes_dataset)):\n",
        "  title = jokes_dataset['title'][joke_index]\n",
        "  text = jokes_dataset['selftext'][joke_index]\n",
        "\n",
        "  title_words = title.split()\n",
        "  text_words = text.split()\n",
        "  final_score = 0\n",
        "  for title_word in title_words:\n",
        "    for text_word in text_words:\n",
        "      s = SequenceMatcher(None,title_word,text_word)\n",
        "      match_freq = s.ratio()\n",
        "      final_score += 1\n",
        "  jokes_dataset['similarity'][joke_index] = final_score\n",
        "  if final_score > max and joke_index in normalised_jokes:\n",
        "    index_similar = joke_index\n",
        "    max = final_score\n",
        "print(jokes_dataset['joke'][index_similar])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Humour_detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
