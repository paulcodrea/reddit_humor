{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulcodrea/reddit_humor/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "kTI_jxV_7R56"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from time import time\n",
        "# from keras.models import Sequential, load_model\n",
        "# from keras.layers.core import Dense, Dropout \n",
        "# from keras.layers import LSTM\n",
        "# from time import time\n",
        "# from keras.callbacks import EarlyStopping\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from pathlib import Path\n",
        "\n",
        "# import nltk\n",
        "# import regex as re\n",
        "# from collections import defaultdict\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "# from nltk.stem.snowball import EnglishStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZzV9t8t87ZOw"
      },
      "outputs": [],
      "source": [
        "# We might have to change the following\n",
        "\n",
        "config = {\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"epochs\": 40, \n",
        "    \"batch_size\": 4,\n",
        "    \"train_p\": 0.55,\n",
        "    \"val_p\": 0.05,\n",
        "    \"LSTM_layer\": [50, 100],\n",
        "    \"Dropout_layer\": [0.15, 0.2],\n",
        "    \"activation\": 'tanh',\n",
        "    \"timesteps\": 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTM_model:\n",
        "    def __init__(self, path):\n",
        "        self.path = path # Path to the dataset\n",
        "        self.data = pd.DataFrame() # Dataframe to store the dataset\n",
        "\n",
        "        self.context_window = 3 # Context window size\n",
        "        self.w2v_feature_vector = []\n",
        "\n",
        "    def read_dataset(self):\n",
        "        \"\"\"\n",
        "        Reads the dataset from the given path.\n",
        "        \"\"\"\n",
        "        ret = pd.read_csv(self.path)\n",
        "        ret.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "        \n",
        "        return ret\n",
        "\n",
        "    def preprocess_text(self):\n",
        "        \"\"\"\n",
        "        Preprocesses the text data.\n",
        "        \"\"\"\n",
        "        self.data['tokens'] = self.data['joke'].apply(word_tokenize) # tokenize the text but keep the punctuation\n",
        "\n",
        "\n",
        "    def construct_word2vec(self):\n",
        "        \"\"\"\n",
        "        Constructs the word2vec model. (Feature vector)\n",
        "        \"\"\"\n",
        "        self.w2v_feature_vector = []\n",
        "        context_words = [] # Construct window list for word2vec\n",
        "        \n",
        "        for line in self.data['tokens']:\n",
        "            for index, word in enumerate(line):\n",
        "                if self.context_window > 0:\n",
        "                    left = index - self.context_window//2\n",
        "                    right = index + self.context_window//2 + 1\n",
        "                else:\n",
        "                    left = index - self.context_window//2\n",
        "                    right = index + self.context_window//2\n",
        "                context_words.append([line[i] for i in range(left, right) if i >= 0 and i < len(line)])\n",
        " \n",
        "\n",
        "        # Create a word2vec model\n",
        "        # context_words = [['a', 'b'], ['a', 'b', 'c'], ['b', 'c', 'd'], ['c', 'd', 'e'], ['d', 'e']] -> list of lists of words and window size is 5\n",
        "        # vector_size = 50 -> dimension of the feature vector (pairs)\n",
        "        # min_count = 4 -> minimum number of occurrences of a word in the corpus\n",
        "        # workers = 4 -> number of threads to use\n",
        "        # window = 5 -> window size\n",
        "        model = Word2Vec(context_words, window=self.context_window, workers=4)\n",
        "\n",
        "        for line in self.data['tokens']:\n",
        "            for index, word in enumerate(line):\n",
        "                if word in model.wv.key_to_index:\n",
        "                    self.w2v_feature_vector.append(model.wv.get_vector(word))\n",
        "                else:\n",
        "                    self.w2v_feature_vector.append(np.zeros(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJL35QEBy-Jz",
        "outputId": "2151be98-c647-49af-d7d4-76e7a6ea5fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['My', '5', 'year', 'old', 'just', 'ran', 'out', 'of', 'her', 'room', 'to', 'tell', 'me', 'this', 'joke', 'she', 'just', 'thought', 'up', ':', 'what', 'did', 'the', 'cow', 'say', 'after', 'he', 'was', 'fed', '?', 'Moooooooooore', '!', 'I', \"'ve\", 'never', 'been', 'this', 'proud', 'of', 'anything', 'in', 'my', 'life', '.']\n",
            "[-0.03717059  0.18439339  0.06661823  0.01248952  0.06323018 -0.47885564\n",
            "  0.08743261  0.58742625 -0.28815296 -0.27545375  0.04169046 -0.462599\n",
            "  0.03613111  0.2198521   0.04350519 -0.17073017  0.15139964 -0.04017985\n",
            " -0.00729127 -0.6064894   0.22195981  0.07907391  0.21248852 -0.07872106\n",
            " -0.16553278  0.08017829 -0.12476471 -0.05605224 -0.24086802  0.10278188\n",
            "  0.30119467  0.00233689  0.10685571 -0.33005694 -0.17532691  0.34755224\n",
            "  0.23784187 -0.23665161 -0.1492309  -0.47725475  0.06649645 -0.38529077\n",
            " -0.16209906 -0.0437514   0.2908809   0.03840032 -0.14959303  0.01834923\n",
            "  0.11771975  0.02263468  0.09958069 -0.26267114  0.00667423  0.01212476\n",
            " -0.08166009  0.14622946  0.13466613 -0.00960764 -0.17603247 -0.02572526\n",
            "  0.16633826  0.03133113  0.14291045  0.11817631 -0.23450205  0.49393713\n",
            " -0.02305235  0.3251643  -0.3152297   0.41739765 -0.26325196  0.228228\n",
            "  0.34933776  0.05726319  0.43585187  0.2503566  -0.05166854  0.03986022\n",
            " -0.26758328 -0.00684477 -0.10368251 -0.1366637  -0.28555286  0.41940024\n",
            " -0.12595405 -0.1007916   0.13898489  0.20030616  0.34884802  0.09724145\n",
            "  0.4825439   0.09792157 -0.03887895  0.09393543  0.44841644  0.28781104\n",
            "  0.11991909 -0.37569514  0.04765188 -0.10231431]\n"
          ]
        }
      ],
      "source": [
        "# SETTINGS for local machine - change this for Goolg Colab\n",
        "path = \"dataset/final_jokes(1283).csv\" #\"/content/drive/MyDrive/NLU_Humor-detection/final_jokes(1283).csv\"\n",
        "\n",
        "joke_model = LSTM_model(path)\n",
        "joke_model.data = joke_model.read_dataset()\n",
        "joke_model.preprocess_text()\n",
        "joke_model.construct_word2vec()\n",
        "\n",
        "print(joke_model.data['tokens'][0])\n",
        "print(joke_model.w2v_feature_vector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNJ+LSjkMXZfSgYMmoTLpK7",
      "collapsed_sections": [],
      "include_colab_link": true,
      "mount_file_id": "1j9kXqN1mbP4p8UZmRZX4T4ZLOsXsnFnk",
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
